{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMEw7w8NFnzU7WFMslmiysu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Setup, Load Data, and Clean"],"metadata":{"id":"MCFd4e4BBql5"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OjoLkZn8BiDF","executionInfo":{"status":"ok","timestamp":1759410359654,"user_tz":-330,"elapsed":3871,"user":{"displayName":"Mena Rossini R","userId":"03024307458201324126"}},"outputId":"e02f6962-9ea4-4cc6-f1e0-5efa9554e5fb"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1350583119.py:9: DtypeWarning: Columns (36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df_sampled = pd.read_csv(\"Dataset.csv\")\n"]},{"output_type":"stream","name":"stdout","text":["Data prepared. Unsupervised training size (Normal only): 15148 rows\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import IsolationForest\n","from sklearn.svm import OneClassSVM\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","\n","# --- 1. Load the Cleaned Data ---\n","df_sampled = pd.read_csv(\"Dataset.csv\")\n","\n","# --- 2. Separate Features (X) and Target (y) ---\n","X = df_sampled.drop('Label', axis=1)\n","y = df_sampled['Label']\n","\n","# --- 3. Re-apply the Feature Cleanup (CRITICAL!) ---\n","leaky_cols = [col for col in X.columns if 'Attack Category' in col]\n","leaky_cols.append('FTP Command Count')\n","X = X.drop(columns=leaky_cols, errors='ignore')\n","\n","# --- 4. Critical Fix: Remove NaN in Target (y) ---\n","nan_mask = y.isnull()\n","if nan_mask.any():\n","    X = X[~nan_mask]\n","    y = y[~nan_mask]\n","\n","# --- 5. Split the Data (70% Train, 30% Test, stratified) ---\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y,\n","    test_size=0.3,\n","    random_state=42,\n","    stratify=y\n",")\n","\n","# --- 6. Prepare Unsupervised Training Data (Normal only) ---\n","X_train_normal = X_train[y_train == 0]\n","\n","print(f\"Data prepared. Unsupervised training size (Normal only): {X_train_normal.shape[0]} rows\")"]},{"cell_type":"markdown","source":["Train and Evaluate"],"metadata":{"id":"o1hSfOOUByL1"}},{"cell_type":"code","source":["# Calculate the contamination (Outlier Fraction) for Isolation Forest\n","contamination_rate = y_train.value_counts()[1] / y_train.shape[0]\n","\n","# Initialize and train the Isolation Forest model\n","if_model = IsolationForest(\n","    n_estimators=100,\n","    contamination=contamination_rate, # Tells the model the expected ratio of anomalies\n","    random_state=42,\n","    n_jobs=-1\n",")\n","\n","# IF is trained on the entire training set (X_train), it doesn't need to be normal-only,\n","# but we will train it on normal only for a direct comparison with OCSVM and AE.\n","if_model.fit(X_train_normal)\n","print(\"\\nIsolation Forest training complete (on Normal data).\")\n","\n","# Predict on the Test Set (1 for Normal, -1 for Anomaly). We convert to 0 and 1.\n","y_pred_if = if_model.predict(X_test)\n","y_pred_if = np.where(y_pred_if == 1, 0, 1) # Convert 1 (Normal) to 0, and -1 (Anomaly) to 1\n","\n","# Note: IF doesn't easily provide probabilities for ROC-AUC, so we skip it for now.\n","\n","# Calculate Metrics\n","accuracy_if = accuracy_score(y_test, y_pred_if)\n","precision_if = precision_score(y_test, y_pred_if)\n","recall_if = recall_score(y_test, y_pred_if)\n","f1_if = f1_score(y_test, y_pred_if)\n","\n","print(\"\\n--- Isolation Forest Centralized Baseline Results ---\")\n","print(f\"Accuracy:  {accuracy_if:.4f}\")\n","print(f\"Precision: {precision_if:.4f}\")\n","print(f\"Recall:    {recall_if:.4f}\")\n","print(f\"F1 Score:  {f1_if:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BqBDDlEzB0yh","executionInfo":{"status":"ok","timestamp":1759410365153,"user_tz":-330,"elapsed":780,"user":{"displayName":"Mena Rossini R","userId":"03024307458201324126"}},"outputId":"195f025b-513c-40e6-89a1-435cbb44a963"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Isolation Forest training complete (on Normal data).\n","\n","--- Isolation Forest Centralized Baseline Results ---\n","Accuracy:  0.8977\n","Precision: 0.5502\n","Recall:    0.9978\n","F1 Score:  0.7093\n"]}]}]}