{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN8RwVl4jPESFuZrnsnwd7L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Load Data"],"metadata":{"id":"rSjXUQOO6Z0w"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g_U9UrIS5Rik","executionInfo":{"status":"ok","timestamp":1759408656904,"user_tz":-330,"elapsed":15896,"user":{"displayName":"Mena Rossini R","userId":"03024307458201324126"}},"outputId":"b9c02126-e82d-49d6-b743-b38d20aabd2c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1693574226.py:11: DtypeWarning: Columns (185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df_sampled = pd.read_csv(\"Dataset.csv\")\n"]},{"output_type":"stream","name":"stdout","text":["Warning: Found 1 rows with NaN in the 'Label' column. Dropping these rows.\n","Data re-loaded and split. Training features size: (271502, 199)\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","\n","# --- Load the Cleaned Data ---\n","df_sampled = pd.read_csv(\"Dataset.csv\")\n","\n","# --- Separate Features (X) and Target (y) ---\n","X = df_sampled.drop('Label', axis=1)\n","y = df_sampled['Label']\n","\n","# --- Re-apply the Feature Cleanup (CRITICAL!) ---\n","leaky_cols = [col for col in X.columns if 'Attack Category' in col]\n","leaky_cols.append('FTP Command Count')\n","X = X.drop(columns=leaky_cols, errors='ignore')\n","\n","# -------------------------------------------------------------------\n","# CRITICAL FIX: Remove rows where the target (y) is NaN\n","\n","'''\n","we encountered error due to some null values present in the Label column...\n","it hapens even after data cleaning sometimes when we merge some datatsets\n","\n","'''\n","# -------------------------------------------------------------------\n","nan_mask = y.isnull()\n","if nan_mask.any():\n","    print(f\"Warning: Found {nan_mask.sum()} rows with NaN in the 'Label' column. Dropping these rows.\")\n","    X = X[~nan_mask] # Keep rows where nan_mask is False\n","    y = y[~nan_mask] # Keep rows where nan_mask is False\n","else:\n","    print(\"SUCCESS: Target variable 'y' is clean (no NaNs found).\")\n","# -------------------------------------------------------------------\n","\n","\n","# --- Re-split the Data (70% Train, 30% Test, stratified) ---\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y,\n","    test_size=0.3,\n","    random_state=42,\n","    stratify=y  # Stratification is now safe\n",")\n","\n","print(f\"Data re-loaded and split. Training features size: {X_train.shape}\")"]},{"cell_type":"markdown","source":["Prepare Data for Autoencoder"],"metadata":{"id":"1IXsQ56J6dZH"}},{"cell_type":"code","source":["# Filter the training data to include ONLY Normal (Label = 0) connections\n","X_train_normal = X_train[y_train == 0]\n","\n","print(f\"Autoencoder Training Data size (Normal only): {X_train_normal.shape[0]} rows\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tQBwNi6u6gEb","executionInfo":{"status":"ok","timestamp":1759408664622,"user_tz":-330,"elapsed":145,"user":{"displayName":"Mena Rossini R","userId":"03024307458201324126"}},"outputId":"5bee06db-7840-4896-b610-bbb73cb2e121"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Autoencoder Training Data size (Normal only): 237142 rows\n"]}]},{"cell_type":"markdown","source":["Define and Train the Autoencoder"],"metadata":{"id":"8vbPwcQY6hY1"}},{"cell_type":"code","source":["# Define the Autoencoder Model Architecture\n","input_dim = X_train_normal.shape[1] # The number of features\n","\n","# Encoder\n","input_layer = Input(shape=(input_dim,))\n","encoded = Dense(64, activation='relu')(input_layer)\n","encoded = Dense(32, activation='relu')(encoded)\n","bottleneck = Dense(16, activation='relu', name='bottleneck')(encoded) # Bottleneck layer\n","\n","# Decoder (Mirror Image)\n","decoded = Dense(32, activation='relu')(bottleneck)\n","decoded = Dense(64, activation='relu')(decoded)\n","output_layer = Dense(input_dim, activation='linear')(decoded)\n","\n","# Build the model\n","autoencoder = Model(inputs=input_layer, outputs=output_layer)\n","autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n","\n","print(\"Starting Autoencoder training...\")\n","history = autoencoder.fit(\n","    X_train_normal, X_train_normal, # Input = Output\n","    epochs=50,\n","    batch_size=256,\n","    shuffle=True,\n","    verbose=0\n",")\n","print(\"Autoencoder training complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"46J8chk36jeg","executionInfo":{"status":"ok","timestamp":1759408872602,"user_tz":-330,"elapsed":204867,"user":{"displayName":"Mena Rossini R","userId":"03024307458201324126"}},"outputId":"76f7e752-763e-4d24-d16d-52f3fdedf4d4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting Autoencoder training...\n","Autoencoder training complete.\n"]}]},{"cell_type":"markdown","source":["Evaluate the Autoencoder Baseline"],"metadata":{"id":"_Hkohxmm6m-t"}},{"cell_type":"code","source":["# 1. Find the Anomaly Threshold on the Normal training data\n","reconstructions_train = autoencoder.predict(X_train_normal)\n","mse_train = np.mean(np.power(X_train_normal - reconstructions_train, 2), axis=1)\n","threshold = np.percentile(mse_train, 99) # 99th percentile threshold\n","print(f\"\\nCalculated Anomaly Threshold (99th percentile): {threshold:.6f}\")\n","\n","# 2. Evaluate on the Test Set (contains both Normal and Attack)\n","reconstructions_test = autoencoder.predict(X_test)\n","mse_test = np.mean(np.power(X_test - reconstructions_test, 2), axis=1)\n","\n","# Predict: Attack (1) if error > threshold, Normal (0) otherwise\n","y_pred_ae = (mse_test > threshold).astype(int)\n","\n","# Calculate Metrics\n","roc_auc_ae = roc_auc_score(y_test, mse_test)\n","accuracy_ae = accuracy_score(y_test, y_pred_ae)\n","precision_ae = precision_score(y_test, y_pred_ae)\n","recall_ae = recall_score(y_test, y_pred_ae)\n","f1_ae = f1_score(y_test, y_pred_ae)\n","\n","# Print the Unsupervised Baseline Results\n","print(\"\\n--- Autoencoder Centralized Baseline Results (Unsupervised) ---\")\n","print(f\"Accuracy:  {accuracy_ae:.4f}\")\n","print(f\"Precision: {precision_ae:.4f}\")\n","print(f\"Recall:    {recall_ae:.4f}\")\n","print(f\"F1 Score:  {f1_ae:.4f}\")\n","print(f\"ROC-AUC:   {roc_auc_ae:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_w6F2IA6nwy","executionInfo":{"status":"ok","timestamp":1759408988854,"user_tz":-330,"elapsed":44327,"user":{"displayName":"Mena Rossini R","userId":"03024307458201324126"}},"outputId":"f97b4e22-839b-48da-849f-cfd1f2b74498"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m7411/7411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step\n","\n","Calculated Anomaly Threshold (99th percentile): 0.000056\n","\u001b[1m3637/3637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n","\n","--- Autoencoder Centralized Baseline Results (Unsupervised) ---\n","Accuracy:  0.9760\n","Precision: 0.9235\n","Recall:    0.8839\n","F1 Score:  0.9033\n","ROC-AUC:   0.9937\n"]}]},{"cell_type":"markdown","source":["now to make this into federated we need to split the data (client data)"],"metadata":{"id":"kZ1GPTPY_fS2"}},{"cell_type":"code","source":["#Prepare Data for FL Clients\n","# -------------------------------------------------------------------\n","\n","# We will use the cleaned X and y variables.\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","# Ensure you import numpy and train_test_split if they aren't already imported\n","\n","NUM_CLIENTS = 10\n","client_data_splits = []\n","\n","# Split the data into 10 chunks.\n","X_chunks = np.array_split(X, NUM_CLIENTS)\n","y_chunks = np.array_split(y, NUM_CLIENTS)\n","\n","for i in range(NUM_CLIENTS):\n","    # Split each client's data into their local train and test sets\n","    # We use a 70/30 split for each client's local data\n","    X_train_client, X_test_client, y_train_client, y_test_client = train_test_split(\n","        X_chunks[i], y_chunks[i],\n","        test_size=0.3,\n","        random_state=42,\n","        stratify=y_chunks[i] # Ensures each client has the same attack ratio\n","    )\n","\n","    client_data_splits.append({\n","        'X_train': X_train_client,\n","        'y_train': y_train_client,\n","        'X_test': X_test_client,\n","        'y_test': y_test_client,\n","    })\n","\n","print(f\"Data split across {NUM_CLIENTS} simulated clients.\")\n","print(f\"Example Client 1 Training Data Size: {client_data_splits[0]['X_train'].shape[0]} rows\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ik8yS0v_mWm","executionInfo":{"status":"ok","timestamp":1759409785145,"user_tz":-330,"elapsed":1487,"user":{"displayName":"Mena Rossini R","userId":"03024307458201324126"}},"outputId":"52936915-f62c-4b0f-e2da-0b45a06b4bea"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n","  return bound(*args, **kwds)\n","/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n","  return bound(*args, **kwds)\n"]},{"output_type":"stream","name":"stdout","text":["Data split across 10 simulated clients.\n","Example Client 1 Training Data Size: 27150 rows\n"]}]}]}