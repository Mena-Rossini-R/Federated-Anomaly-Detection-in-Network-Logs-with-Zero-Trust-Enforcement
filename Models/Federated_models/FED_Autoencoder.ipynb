{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPvACWEnLfQs8xjPA/AF1DW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Setup and Data Preparation"],"metadata":{"id":"xUgHfswdW5h1"}},{"cell_type":"markdown","source":["Define the FL Autoencoder Model (Shared Architecture)"],"metadata":{"id":"7HFNFXVwW3Ry"}},{"cell_type":"markdown","source":["Define the Flower Client (The Core Logic)"],"metadata":{"id":"QdGRNEmzWqgE"}},{"cell_type":"markdown","source":[" FL Server and Simulation"],"metadata":{"id":"KP_Gr3rPXBep"}},{"cell_type":"code","source":["# --- CRITICAL: INSTALL LATEST STABLE FLOWER VERSION ---\n","# This version handles Ray/Python 3.12 compatibility\n","!pip install -U --force-reinstall \"flwr[simulation]\" tensorflow scikit-learn numpy pandas"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Uj0kabvQY3x4","executionInfo":{"status":"ok","timestamp":1759419236108,"user_tz":-330,"elapsed":224041,"user":{"displayName":"Mena Rossini R","userId":"03024307458201324126"}},"outputId":"e38b5a74-14e3-4c7a-acaf-3cdb5fff7de6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow\n","  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n","Collecting scikit-learn\n","  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n","Collecting numpy\n","  Downloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pandas\n","  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flwr[simulation]\n","  Using cached flwr-1.22.0-py3-none-any.whl.metadata (14 kB)\n","Collecting click<8.2.0 (from flwr[simulation])\n","  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n","Collecting cryptography<45.0.0,>=44.0.1 (from flwr[simulation])\n","  Using cached cryptography-44.0.3-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n","Collecting grpcio!=1.65.0,<2.0.0,>=1.62.3 (from flwr[simulation])\n","  Downloading grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n","Collecting grpcio-health-checking<2.0.0,>=1.62.3 (from flwr[simulation])\n","  Using cached grpcio_health_checking-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n","Collecting iterators<0.0.3,>=0.0.2 (from flwr[simulation])\n","  Using cached iterators-0.0.2-py3-none-any.whl.metadata (2.5 kB)\n","Collecting pathspec<0.13.0,>=0.12.1 (from flwr[simulation])\n","  Using cached pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n","Collecting protobuf<5.0.0,>=4.21.6 (from flwr[simulation])\n","  Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n","Collecting pycryptodome<4.0.0,>=3.18.0 (from flwr[simulation])\n","  Using cached pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Collecting pyyaml<7.0.0,>=6.0.2 (from flwr[simulation])\n","  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n","Collecting ray==2.31.0 (from flwr[simulation])\n","  Using cached ray-2.31.0-cp312-cp312-manylinux2014_x86_64.whl.metadata (13 kB)\n","Collecting requests<3.0.0,>=2.31.0 (from flwr[simulation])\n","  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n","Collecting rich<14.0.0,>=13.5.0 (from flwr[simulation])\n","  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n","Collecting tomli<3.0.0,>=2.0.1 (from flwr[simulation])\n","  Using cached tomli-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Collecting tomli-w<2.0.0,>=1.0.0 (from flwr[simulation])\n","  Using cached tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n","Collecting typer<0.13.0,>=0.12.5 (from flwr[simulation])\n","  Using cached typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n","Collecting filelock (from ray==2.31.0->flwr[simulation])\n","  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n","Collecting jsonschema (from ray==2.31.0->flwr[simulation])\n","  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n","Collecting msgpack<2.0.0,>=1.0.0 (from ray==2.31.0->flwr[simulation])\n","  Downloading msgpack-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n","Collecting packaging (from ray==2.31.0->flwr[simulation])\n","  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n","Collecting aiosignal (from ray==2.31.0->flwr[simulation])\n","  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n","Collecting frozenlist (from ray==2.31.0->flwr[simulation])\n","  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n","Collecting absl-py>=1.0.0 (from tensorflow)\n","  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n","Collecting astunparse>=1.6.0 (from tensorflow)\n","  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n","Collecting flatbuffers>=24.3.25 (from tensorflow)\n","  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n","Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n","  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n","Collecting google_pasta>=0.1.1 (from tensorflow)\n","  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n","Collecting libclang>=13.0.0 (from tensorflow)\n","  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n","Collecting opt_einsum>=2.3.2 (from tensorflow)\n","  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n","INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow\n","  Downloading tensorflow-2.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n","Collecting setuptools (from tensorflow)\n","  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n","Collecting six>=1.12.0 (from tensorflow)\n","  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n","Collecting termcolor>=1.1.0 (from tensorflow)\n","  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n","Collecting typing-extensions>=3.6.6 (from tensorflow)\n","  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n","Collecting wrapt>=1.11.0 (from tensorflow)\n","  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n","Collecting tensorboard~=2.19.0 (from tensorflow)\n","  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n","Collecting keras>=3.5.0 (from tensorflow)\n","  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n","Collecting numpy\n","  Downloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h5py>=3.11.0 (from tensorflow)\n","  Downloading h5py-3.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n","Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n","  Downloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n","Collecting scipy>=1.8.0 (from scikit-learn)\n","  Downloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n","  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n","Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n","  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n","Collecting python-dateutil>=2.8.2 (from pandas)\n","  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n","Collecting pytz>=2020.1 (from pandas)\n","  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n","Collecting tzdata>=2022.7 (from pandas)\n","  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n","  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n","Collecting cffi>=1.12 (from cryptography<45.0.0,>=44.0.1->flwr[simulation])\n","  Downloading cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n","INFO: pip is looking at multiple versions of grpcio-health-checking to determine which version is compatible with other requirements. This could take a while.\n","Collecting grpcio-health-checking<2.0.0,>=1.62.3 (from flwr[simulation])\n","  Using cached grpcio_health_checking-1.75.0-py3-none-any.whl.metadata (1.0 kB)\n","  Using cached grpcio_health_checking-1.74.0-py3-none-any.whl.metadata (1.0 kB)\n","  Using cached grpcio_health_checking-1.73.1-py3-none-any.whl.metadata (1.0 kB)\n","  Using cached grpcio_health_checking-1.73.0-py3-none-any.whl.metadata (1.0 kB)\n","  Using cached grpcio_health_checking-1.72.2-py3-none-any.whl.metadata (1.0 kB)\n","  Using cached grpcio_health_checking-1.72.1-py3-none-any.whl.metadata (1.0 kB)\n","  Using cached grpcio_health_checking-1.71.2-py3-none-any.whl.metadata (1.0 kB)\n","INFO: pip is still looking at multiple versions of grpcio-health-checking to determine which version is compatible with other requirements. This could take a while.\n","  Using cached grpcio_health_checking-1.71.0-py3-none-any.whl.metadata (1.0 kB)\n","  Using cached grpcio_health_checking-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Using cached grpcio_health_checking-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n","  Using cached grpcio_health_checking-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n","Collecting namex (from keras>=3.5.0->tensorflow)\n","  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n","Collecting optree (from keras>=3.5.0->tensorflow)\n","  Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n","Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.31.0->flwr[simulation])\n","  Downloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n","Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.31.0->flwr[simulation])\n","  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n","Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.31.0->flwr[simulation])\n","  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n","Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.31.0->flwr[simulation])\n","  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n","Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=13.5.0->flwr[simulation])\n","  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n","Collecting pygments<3.0.0,>=2.13.0 (from rich<14.0.0,>=13.5.0->flwr[simulation])\n","  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n","Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n","  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n","Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n","  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n","Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n","  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n","Collecting shellingham>=1.3.0 (from typer<0.13.0,>=0.12.5->flwr[simulation])\n","  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n","Collecting pycparser (from cffi>=1.12->cryptography<45.0.0,>=44.0.1->flwr[simulation])\n","  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n","Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr[simulation])\n","  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n","Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow)\n","  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n","Collecting attrs>=22.2.0 (from jsonschema->ray==2.31.0->flwr[simulation])\n","  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n","Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->ray==2.31.0->flwr[simulation])\n","  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n","Collecting referencing>=0.28.4 (from jsonschema->ray==2.31.0->flwr[simulation])\n","  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n","Collecting rpds-py>=0.7.1 (from jsonschema->ray==2.31.0->flwr[simulation])\n","  Downloading rpds_py-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Using cached ray-2.31.0-cp312-cp312-manylinux2014_x86_64.whl (66.7 MB)\n","Downloading tensorflow-2.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (645.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.0/645.0 MB\u001b[0m \u001b[31m787.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Using cached click-8.1.8-py3-none-any.whl (98 kB)\n","Using cached cryptography-44.0.3-cp39-abi3-manylinux_2_34_x86_64.whl (4.2 MB)\n","Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n","Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n","Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached grpcio_health_checking-1.62.3-py3-none-any.whl (18 kB)\n","Downloading h5py-3.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached iterators-0.0.2-py3-none-any.whl (3.9 kB)\n","Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.4/308.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached pathspec-0.12.1-py3-none-any.whl (31 kB)\n","Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","Using cached pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n","Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n","Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n","Using cached tomli-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n","Using cached tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n","Using cached typer-0.12.5-py3-none-any.whl (47 kB)\n","Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m923.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached flwr-1.22.0-py3-none-any.whl (703 kB)\n","Downloading packaging-25.0-py3-none-any.whl (66 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (219 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.6/219.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading markdown-3.9-py3-none-any.whl (107 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading msgpack-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.9/426.9 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n","Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n","Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.8/241.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filelock-3.19.1-py3-none-any.whl (15 kB)\n","Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n","Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (408 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.8/408.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading attrs-25.3.0-py3-none-any.whl (63 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n","Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n","Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n","Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n","Downloading rpds_py-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycparser-2.23-py3-none-any.whl (118 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pytz, namex, libclang, flatbuffers, wrapt, wheel, urllib3, tzdata, typing-extensions, tomli-w, tomli, threadpoolctl, termcolor, tensorboard-data-server, six, shellingham, setuptools, rpds-py, pyyaml, pygments, pycryptodome, pycparser, protobuf, pathspec, packaging, opt_einsum, numpy, msgpack, mdurl, MarkupSafe, markdown, joblib, iterators, idna, gast, frozenlist, filelock, click, charset_normalizer, certifi, attrs, absl-py, werkzeug, scipy, requests, referencing, python-dateutil, optree, ml-dtypes, markdown-it-py, h5py, grpcio, google_pasta, cffi, astunparse, aiosignal, tensorboard, scikit-learn, rich, pandas, jsonschema-specifications, grpcio-health-checking, cryptography, typer, keras, jsonschema, tensorflow, ray, flwr\n","  Attempting uninstall: pytz\n","    Found existing installation: pytz 2025.2\n","    Uninstalling pytz-2025.2:\n","      Successfully uninstalled pytz-2025.2\n","  Attempting uninstall: namex\n","    Found existing installation: namex 0.1.0\n","    Uninstalling namex-0.1.0:\n","      Successfully uninstalled namex-0.1.0\n","  Attempting uninstall: libclang\n","    Found existing installation: libclang 18.1.1\n","    Uninstalling libclang-18.1.1:\n","      Successfully uninstalled libclang-18.1.1\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 25.2.10\n","    Uninstalling flatbuffers-25.2.10:\n","      Successfully uninstalled flatbuffers-25.2.10\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.17.3\n","    Uninstalling wrapt-1.17.3:\n","      Successfully uninstalled wrapt-1.17.3\n","  Attempting uninstall: wheel\n","    Found existing installation: wheel 0.45.1\n","    Uninstalling wheel-0.45.1:\n","      Successfully uninstalled wheel-0.45.1\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.5.0\n","    Uninstalling urllib3-2.5.0:\n","      Successfully uninstalled urllib3-2.5.0\n","  Attempting uninstall: tzdata\n","    Found existing installation: tzdata 2025.2\n","    Uninstalling tzdata-2025.2:\n","      Successfully uninstalled tzdata-2025.2\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.15.0\n","    Uninstalling typing_extensions-4.15.0:\n","      Successfully uninstalled typing_extensions-4.15.0\n","  Attempting uninstall: tomli-w\n","    Found existing installation: tomli_w 1.2.0\n","    Uninstalling tomli_w-1.2.0:\n","      Successfully uninstalled tomli_w-1.2.0\n","  Attempting uninstall: tomli\n","    Found existing installation: tomli 2.2.1\n","    Uninstalling tomli-2.2.1:\n","      Successfully uninstalled tomli-2.2.1\n","  Attempting uninstall: threadpoolctl\n","    Found existing installation: threadpoolctl 3.6.0\n","    Uninstalling threadpoolctl-3.6.0:\n","      Successfully uninstalled threadpoolctl-3.6.0\n","  Attempting uninstall: termcolor\n","    Found existing installation: termcolor 3.1.0\n","    Uninstalling termcolor-3.1.0:\n","      Successfully uninstalled termcolor-3.1.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.2\n","    Uninstalling tensorboard-data-server-0.7.2:\n","      Successfully uninstalled tensorboard-data-server-0.7.2\n","  Attempting uninstall: six\n","    Found existing installation: six 1.17.0\n","    Uninstalling six-1.17.0:\n","      Successfully uninstalled six-1.17.0\n","  Attempting uninstall: shellingham\n","    Found existing installation: shellingham 1.5.4\n","    Uninstalling shellingham-1.5.4:\n","      Successfully uninstalled shellingham-1.5.4\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 75.2.0\n","    Uninstalling setuptools-75.2.0:\n","      Successfully uninstalled setuptools-75.2.0\n","  Attempting uninstall: rpds-py\n","    Found existing installation: rpds-py 0.27.1\n","    Uninstalling rpds-py-0.27.1:\n","      Successfully uninstalled rpds-py-0.27.1\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0.2\n","    Uninstalling PyYAML-6.0.2:\n","      Successfully uninstalled PyYAML-6.0.2\n","  Attempting uninstall: pygments\n","    Found existing installation: Pygments 2.19.2\n","    Uninstalling Pygments-2.19.2:\n","      Successfully uninstalled Pygments-2.19.2\n","  Attempting uninstall: pycryptodome\n","    Found existing installation: pycryptodome 3.23.0\n","    Uninstalling pycryptodome-3.23.0:\n","      Successfully uninstalled pycryptodome-3.23.0\n","  Attempting uninstall: pycparser\n","    Found existing installation: pycparser 2.23\n","    Uninstalling pycparser-2.23:\n","      Successfully uninstalled pycparser-2.23\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 4.25.8\n","    Uninstalling protobuf-4.25.8:\n","      Successfully uninstalled protobuf-4.25.8\n","  Attempting uninstall: pathspec\n","    Found existing installation: pathspec 0.12.1\n","    Uninstalling pathspec-0.12.1:\n","      Successfully uninstalled pathspec-0.12.1\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 25.0\n","    Uninstalling packaging-25.0:\n","      Successfully uninstalled packaging-25.0\n","  Attempting uninstall: opt_einsum\n","    Found existing installation: opt_einsum 3.4.0\n","    Uninstalling opt_einsum-3.4.0:\n","      Successfully uninstalled opt_einsum-3.4.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: msgpack\n","    Found existing installation: msgpack 1.1.1\n","    Uninstalling msgpack-1.1.1:\n","      Successfully uninstalled msgpack-1.1.1\n","  Attempting uninstall: mdurl\n","    Found existing installation: mdurl 0.1.2\n","    Uninstalling mdurl-0.1.2:\n","      Successfully uninstalled mdurl-0.1.2\n","  Attempting uninstall: MarkupSafe\n","    Found existing installation: MarkupSafe 3.0.2\n","    Uninstalling MarkupSafe-3.0.2:\n","      Successfully uninstalled MarkupSafe-3.0.2\n","  Attempting uninstall: markdown\n","    Found existing installation: Markdown 3.9\n","    Uninstalling Markdown-3.9:\n","      Successfully uninstalled Markdown-3.9\n","  Attempting uninstall: joblib\n","    Found existing installation: joblib 1.5.2\n","    Uninstalling joblib-1.5.2:\n","      Successfully uninstalled joblib-1.5.2\n","  Attempting uninstall: iterators\n","    Found existing installation: iterators 0.0.2\n","    Uninstalling iterators-0.0.2:\n","      Successfully uninstalled iterators-0.0.2\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.10\n","    Uninstalling idna-3.10:\n","      Successfully uninstalled idna-3.10\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.6.0\n","    Uninstalling gast-0.6.0:\n","      Successfully uninstalled gast-0.6.0\n","  Attempting uninstall: frozenlist\n","    Found existing installation: frozenlist 1.7.0\n","    Uninstalling frozenlist-1.7.0:\n","      Successfully uninstalled frozenlist-1.7.0\n","  Attempting uninstall: filelock\n","    Found existing installation: filelock 3.19.1\n","    Uninstalling filelock-3.19.1:\n","      Successfully uninstalled filelock-3.19.1\n","  Attempting uninstall: click\n","    Found existing installation: click 8.1.8\n","    Uninstalling click-8.1.8:\n","      Successfully uninstalled click-8.1.8\n","  Attempting uninstall: charset_normalizer\n","    Found existing installation: charset-normalizer 3.4.3\n","    Uninstalling charset-normalizer-3.4.3:\n","      Successfully uninstalled charset-normalizer-3.4.3\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2025.8.3\n","    Uninstalling certifi-2025.8.3:\n","      Successfully uninstalled certifi-2025.8.3\n","  Attempting uninstall: attrs\n","    Found existing installation: attrs 25.3.0\n","    Uninstalling attrs-25.3.0:\n","      Successfully uninstalled attrs-25.3.0\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.4.0\n","    Uninstalling absl-py-1.4.0:\n","      Successfully uninstalled absl-py-1.4.0\n","  Attempting uninstall: werkzeug\n","    Found existing installation: Werkzeug 3.1.3\n","    Uninstalling Werkzeug-3.1.3:\n","      Successfully uninstalled Werkzeug-3.1.3\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.16.2\n","    Uninstalling scipy-1.16.2:\n","      Successfully uninstalled scipy-1.16.2\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.32.4\n","    Uninstalling requests-2.32.4:\n","      Successfully uninstalled requests-2.32.4\n","  Attempting uninstall: referencing\n","    Found existing installation: referencing 0.36.2\n","    Uninstalling referencing-0.36.2:\n","      Successfully uninstalled referencing-0.36.2\n","  Attempting uninstall: python-dateutil\n","    Found existing installation: python-dateutil 2.9.0.post0\n","    Uninstalling python-dateutil-2.9.0.post0:\n","      Successfully uninstalled python-dateutil-2.9.0.post0\n","  Attempting uninstall: optree\n","    Found existing installation: optree 0.17.0\n","    Uninstalling optree-0.17.0:\n","      Successfully uninstalled optree-0.17.0\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml_dtypes 0.5.3\n","    Uninstalling ml_dtypes-0.5.3:\n","      Successfully uninstalled ml_dtypes-0.5.3\n","  Attempting uninstall: markdown-it-py\n","    Found existing installation: markdown-it-py 4.0.0\n","    Uninstalling markdown-it-py-4.0.0:\n","      Successfully uninstalled markdown-it-py-4.0.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.14.0\n","    Uninstalling h5py-3.14.0:\n","      Successfully uninstalled h5py-3.14.0\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.75.0\n","    Uninstalling grpcio-1.75.0:\n","      Successfully uninstalled grpcio-1.75.0\n","  Attempting uninstall: google_pasta\n","    Found existing installation: google-pasta 0.2.0\n","    Uninstalling google-pasta-0.2.0:\n","      Successfully uninstalled google-pasta-0.2.0\n","  Attempting uninstall: cffi\n","    Found existing installation: cffi 2.0.0\n","    Uninstalling cffi-2.0.0:\n","      Successfully uninstalled cffi-2.0.0\n","  Attempting uninstall: astunparse\n","    Found existing installation: astunparse 1.6.3\n","    Uninstalling astunparse-1.6.3:\n","      Successfully uninstalled astunparse-1.6.3\n","  Attempting uninstall: aiosignal\n","    Found existing installation: aiosignal 1.4.0\n","    Uninstalling aiosignal-1.4.0:\n","      Successfully uninstalled aiosignal-1.4.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.19.0\n","    Uninstalling tensorboard-2.19.0:\n","      Successfully uninstalled tensorboard-2.19.0\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.6.1\n","    Uninstalling scikit-learn-1.6.1:\n","      Successfully uninstalled scikit-learn-1.6.1\n","  Attempting uninstall: rich\n","    Found existing installation: rich 13.9.4\n","    Uninstalling rich-13.9.4:\n","      Successfully uninstalled rich-13.9.4\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.2\n","    Uninstalling pandas-2.2.2:\n","      Successfully uninstalled pandas-2.2.2\n","  Attempting uninstall: jsonschema-specifications\n","    Found existing installation: jsonschema-specifications 2025.9.1\n","    Uninstalling jsonschema-specifications-2025.9.1:\n","      Successfully uninstalled jsonschema-specifications-2025.9.1\n","  Attempting uninstall: grpcio-health-checking\n","    Found existing installation: grpcio-health-checking 1.62.3\n","    Uninstalling grpcio-health-checking-1.62.3:\n","      Successfully uninstalled grpcio-health-checking-1.62.3\n","  Attempting uninstall: cryptography\n","    Found existing installation: cryptography 44.0.3\n","    Uninstalling cryptography-44.0.3:\n","      Successfully uninstalled cryptography-44.0.3\n","  Attempting uninstall: typer\n","    Found existing installation: typer 0.12.5\n","    Uninstalling typer-0.12.5:\n","      Successfully uninstalled typer-0.12.5\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.10.0\n","    Uninstalling keras-3.10.0:\n","      Successfully uninstalled keras-3.10.0\n","  Attempting uninstall: jsonschema\n","    Found existing installation: jsonschema 4.25.1\n","    Uninstalling jsonschema-4.25.1:\n","      Successfully uninstalled jsonschema-4.25.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.19.0\n","    Uninstalling tensorflow-2.19.0:\n","      Successfully uninstalled tensorflow-2.19.0\n","  Attempting uninstall: ray\n","    Found existing installation: ray 2.31.0\n","    Uninstalling ray-2.31.0:\n","      Successfully uninstalled ray-2.31.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.3 which is incompatible.\n","tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.19.1 which is incompatible.\n","ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n","grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n","dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n","pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\n","pyopenssl 24.2.1 requires cryptography<44,>=41.0.5, but you have cryptography 44.0.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed MarkupSafe-3.0.3 absl-py-2.3.1 aiosignal-1.4.0 astunparse-1.6.3 attrs-25.3.0 certifi-2025.8.3 cffi-2.0.0 charset_normalizer-3.4.3 click-8.1.8 cryptography-44.0.3 filelock-3.19.1 flatbuffers-25.9.23 flwr-1.22.0 frozenlist-1.7.0 gast-0.6.0 google_pasta-0.2.0 grpcio-1.75.1 grpcio-health-checking-1.62.3 h5py-3.14.0 idna-3.10 iterators-0.0.2 joblib-1.5.2 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 keras-3.11.3 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 ml-dtypes-0.5.3 msgpack-1.1.1 namex-0.1.0 numpy-2.1.3 opt_einsum-3.4.0 optree-0.17.0 packaging-25.0 pandas-2.3.3 pathspec-0.12.1 protobuf-4.25.8 pycparser-2.23 pycryptodome-3.23.0 pygments-2.19.2 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 ray-2.31.0 referencing-0.36.2 requests-2.32.5 rich-13.9.4 rpds-py-0.27.1 scikit-learn-1.7.2 scipy-1.16.2 setuptools-80.9.0 shellingham-1.5.4 six-1.17.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.1 termcolor-3.1.0 threadpoolctl-3.6.0 tomli-2.2.1 tomli-w-1.2.0 typer-0.12.5 typing-extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["Crypto","_cffi_backend","_distutils_hack","_openssl","absl","astunparse","attr","certifi","cffi","cryptography","dateutil","filelock","flatbuffers","gast","google","h5py","idna","joblib","keras","namex","numpy","opt_einsum","optree","packaging","pandas","pycparser","pytz","requests","rich","scipy","six","sklearn","tensorflow","termcolor","threadpoolctl","urllib3","wrapt"]},"id":"2ffd65f7e3e3434d9ba6e92aafce14ce"}},"metadata":{}}]},{"cell_type":"code","source":["# -------------------------------------------------------------------\n","# STEP 0: SETUP AND IMPORTS\n","# -------------------------------------------------------------------\n","\n","# 1. Install necessary dependencies (ensure \"flwr[simulation]\" is installed)\n","# NOTE: You must run this command and then click 'RESTART RUNTIME' in Colab\n","# before running the rest of the code block for Ray to load correctly.\n","# !pip install -U \"flwr[simulation]\" tensorflow scikit-learn numpy pandas\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import Input, Dense\n","import flwr as fl\n","from flwr.common import ndarrays_to_parameters, parameters_to_ndarrays\n","from sklearn.metrics import roc_auc_score\n","from collections import Counter\n","\n","# -------------------------------------------------------------------\n","# STEP 1: DATA PREPARATION (Final Corrected Cleanup)\n","# -------------------------------------------------------------------\n","print(\"1. Loading and Cleaning Data...\")\n","df_sampled = pd.read_csv(\"Dataset.csv\", low_memory=False)\n","\n","# A. Separate Features and Target\n","X = df_sampled.drop('Label', axis=1)\n","y = df_sampled['Label']\n","\n","# B. Cleanup: Drop leaky columns, handle NaNs\n","leaky_cols = [col for col in X.columns if 'Attack Category' in col]\n","leaky_cols.append('FTP Command Count')\n","X = X.drop(columns=leaky_cols, errors='ignore')\n","\n","nan_mask = y.isnull()\n","X = X[~nan_mask]\n","y = y[~nan_mask]\n","\n","for col in X.columns:\n","    X[col] = pd.to_numeric(X[col], errors='coerce')\n","X = X.fillna(0)\n","\n","# C. Define global variables and CRITICAL type casting\n","input_dim = X.shape[1]\n","NUM_CLIENTS = 10\n","\n","# Define the global test set (CRITICAL: Cast to float32 for Keras/TF)\n","X_test_global_np = X.to_numpy().astype('float32')\n","y_test_global_np = y.to_numpy().astype('float32')\n","print(f\"Data ready. Final feature count: {input_dim}\")\n","\n","\n","# -------------------------------------------------------------------\n","# STEP 2: FL DATA PARTITIONING (Client Splits)\n","# -------------------------------------------------------------------\n","print(\"2. Partitioning Data for FL Clients...\")\n","client_data_splits = []\n","\n","X_chunks = np.array_split(X, NUM_CLIENTS)\n","y_chunks = np.array_split(y, NUM_CLIENTS)\n","\n","for i in range(NUM_CLIENTS):\n","    X_train_client, X_test_client, y_train_client, y_test_client = train_test_split(\n","        X_chunks[i], y_chunks[i],\n","        test_size=0.3, random_state=42, stratify=y_chunks[i]\n","    )\n","\n","    # Autoencoder only trains on NORMAL data\n","    X_train_normal = X_train_client[y_train_client == 0]\n","\n","    client_data_splits.append({\n","        # CRITICAL: Cast all client data to float32\n","        'X_train_normal': X_train_normal.to_numpy().astype('float32'),\n","        'X_test': X_test_client.to_numpy().astype('float32'),\n","        'y_test': y_test_client.to_numpy().astype('float32'),\n","    })\n","print(f\"Data split across {NUM_CLIENTS} simulated clients.\")\n","\n","\n","# -------------------------------------------------------------------\n","# STEP 3: MODEL DEFINITION (Shared Architecture)\n","# -------------------------------------------------------------------\n","def create_autoencoder(input_dim):\n","    # Encoder (Bottleneck layer)\n","    input_layer = Input(shape=(input_dim,))\n","    encoded = Dense(64, activation='relu')(input_layer)\n","    bottleneck = Dense(16, activation='relu', name='bottleneck')(encoded)\n","\n","    # Decoder (Mirror Image)\n","    decoded = Dense(64, activation='relu')(bottleneck)\n","    output_layer = Dense(input_dim, activation='linear')(decoded)\n","\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    model.compile(optimizer='adam', loss='mse')\n","    return model\n","print(\"3. Autoencoder model architecture defined.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HHuPzD91bPEa","executionInfo":{"status":"ok","timestamp":1759419325815,"user_tz":-330,"elapsed":67414,"user":{"displayName":"Mena Rossini R","userId":"03024307458201324126"}},"outputId":"5b0a29bf-a9ed-442c-9406-55f5abfe4b5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1. Loading and Cleaning Data...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(tzinfo=utc)\n"]},{"output_type":"stream","name":"stdout","text":["Data ready. Final feature count: 199\n","2. Partitioning Data for FL Clients...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n","  return bound(*args, **kwds)\n","/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(tzinfo=utc)\n","/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n","  return bound(*args, **kwds)\n","/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(tzinfo=utc)\n"]},{"output_type":"stream","name":"stdout","text":["Data split across 10 simulated clients.\n","3. Autoencoder model architecture defined.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(tzinfo=utc)\n"]}]},{"cell_type":"code","source":["# In Block 2 (Step 4: FL CLIENT LOGIC)\n","\n","class FederatedAutoencoderClient(fl.client.NumPyClient):\n","    # ... (init remains the same)\n","\n","    def get_parameters(self, config):\n","        # Standard implementation\n","        return self.model.get_weights()\n","\n","    def fit(self, parameters, config):\n","        # Update local model with global parameters (NO manual unwrapping needed)\n","        self.model.set_weights(fl.common.parameters_to_ndarrays(parameters))\n","\n","        # Train locally on local NORMAL data (Input = Output)\n","        X_train = self.data['X_train_normal']\n","\n","        self.model.fit(\n","            X_train, X_train,\n","            epochs=1,     # <-- Keep 1 epoch\n","            batch_size=16, # <-- CRITICAL: Reduce batch size from 32 to 16\n","            verbose=0\n","        )\n","\n","        # Return updated local weights, size, and metrics dict\n","        # Standard implementation\n","        return fl.common.ndarrays_to_parameters(self.model.get_weights()), len(X_train), {}\n","\n","    # ... (evaluate remains the same)\n","    def evaluate(self, parameters, config):\n","        # Evaluation is done by the server for clean comparison\n","        return 0.0, 0, {}\n","\n","# FIX for client_fn to handle NumPyClient return compatibility\n","def client_fn(cid: str) -> fl.client.Client:\n","    return FederatedAutoencoderClient(int(cid)).to_client() # <--- Explicit conversion FIX\n","\n","print(\"4. Federated Client logic redefined with RAW weight handling.\")\n","\n","# -------------------------------------------------------------------\n","# CRITICAL NOTE: The Server-side needs a minor adjustment too.\n","# The `initial_parameters` and `fit` method will now work without conversion utilities.\n","# The server-side evaluation (Step 5) must also be updated.\n","# -------------------------------------------------------------------"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J8hWn2yLdNJQ","executionInfo":{"status":"ok","timestamp":1759422005668,"user_tz":-330,"elapsed":14,"user":{"displayName":"Mena Rossini R","userId":"03024307458201324126"}},"outputId":"39d95963-2a8e-4d3f-ba52-b9a6ca5a55cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4. Federated Client logic redefined with RAW weight handling.\n"]}]},{"cell_type":"code","source":["from flwr.common import ndarrays_to_parameters\n","from sklearn.metrics import roc_auc_score\n","import flwr as fl\n","\n","# -------------------------------------------------------------------\n","# 1. Server-Side Global Evaluation Function\n","# -------------------------------------------------------------------\n","def evaluate_global_model(server_round: int, parameters, config: dict):\n","    # This function is now used ONLY for reporting, not for initialization\n","    model = create_autoencoder(input_dim)\n","\n","    # Direct use of weights list (NumPy arrays)\n","    model.set_weights(parameters)\n","\n","    # Predict reconstruction error on the global test set\n","    reconstructions = model.predict(X_test_global_np, verbose=0)\n","    mse = np.mean(np.power(X_test_global_np - reconstructions, 2), axis=1)\n","\n","    try:\n","        global_roc_auc = roc_auc_score(y_test_global_np, mse)\n","    except ValueError:\n","        global_roc_auc = 0.0\n","\n","    print(f\"Server Round {server_round}: Global ROC-AUC = {global_roc_auc:.4f}\")\n","\n","    # Return 1 - AUC as the loss\n","    return 1.0 - global_roc_auc, {\"roc_auc\": global_roc_auc}\n","\n","\n","# -------------------------------------------------------------------\n","# 2. Define the Strategy (FedAvg) - MODIFIED\n","# -------------------------------------------------------------------\n","strategy = fl.server.strategy.FedAvg(\n","    fraction_fit=0.5,\n","    fraction_evaluate=0.5,\n","    min_fit_clients=5,\n","    min_available_clients=NUM_CLIENTS,\n","    initial_parameters=create_autoencoder(input_dim).get_weights(),\n","\n","    # CRITICAL FIX: Set evaluate_fn to None during initialization,\n","    # and then run evaluation later.\n","    evaluate_fn=None, # <--- TEMPORARILY DISABLED BUGGY INITIAL EVALUATION\n","\n","    # Optional: You can re-enable evaluation after Round 1 if needed for paper tracking:\n","    # on_evaluate_config_fn=lambda rnd: {\"round_num\": rnd} if rnd > 0 else {}\n",")\n","\n","# -------------------------------------------------------------------\n","# 3. Start the Simulation\n","# -------------------------------------------------------------------\n","print(\"\\n5. Starting Federated Learning Simulation (FedAE)...\")\n","history = fl.simulation.start_simulation(\n","    client_fn=client_fn,\n","    num_clients=NUM_CLIENTS,\n","    config=fl.server.ServerConfig(num_rounds=15),\n","    strategy=strategy,\n",")\n","\n","# NOTE: Since we disabled the evaluation in the strategy, the output will only show\n","# the aggregation rounds. We will analyze the final model from the 'history' object.\n","print(\"Federated Learning Simulation Complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hom5jTe_gtXT","executionInfo":{"status":"ok","timestamp":1759422036291,"user_tz":-330,"elapsed":27053,"user":{"displayName":"Mena Rossini R","userId":"03024307458201324126"}},"outputId":"0dd8837a-c3d5-4302-a049-dafa03d3c7cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n","\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n","\n","\t\t$ flwr new  # Create a new Flower app from a template\n","\n","\t\t$ flwr run  # Run the Flower app in Simulation Mode\n","\n","\tUsing `start_simulation()` is deprecated.\n","\n","            This is a deprecated feature. It will be removed\n","            entirely in future versions of Flower.\n","        \n","\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=15, no round_timeout\n"]},{"output_type":"stream","name":"stdout","text":["\n","5. Starting Federated Learning Simulation (FedAE)...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(tzinfo=utc)\n","2025-10-02 16:20:24,624\tINFO worker.py:1771 -- Started a local Ray instance.\n","\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'object_store_memory': 3915222220.0, 'memory': 7830444443.0}\n","\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n","\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n","\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n","\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n","\u001b[92mINFO \u001b[0m:      [INIT]\n","\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n","\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n","\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 1]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 2]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 3]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 4]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 5]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 6]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 7]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 8]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 9]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 10]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 11]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 12]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 13]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 14]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 15]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 5 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [SUMMARY]\n","\u001b[92mINFO \u001b[0m:      Run finished 15 round(s) in 0.71s\n","\u001b[92mINFO \u001b[0m:      \n"]},{"output_type":"stream","name":"stdout","text":["Federated Learning Simulation Complete.\n"]}]},{"cell_type":"markdown","source":["New"],"metadata":{"id":"_JMnbXQxwh6x"}},{"cell_type":"code","source":["# CRITICAL: Install TFF and Keras\n","!pip install --quiet tensorflow-federated==0.59.0 tensorflow-cpu==2.15.0 keras==2.15.0\n","# The above versions are known to be compatible in Colab as of the latest TFF release.\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K4P-mBpmwhlK","executionInfo":{"status":"ok","timestamp":1759472944420,"user_tz":-330,"elapsed":5328,"user":{"displayName":"Mena Rossini R","userId":"03024307458201324126"}},"outputId":"f91606c0-f977-43c8-f11e-fb2dc617fa99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Ignored the following versions that require a different python version: 0.34.0 Requires-Python ~=3.9.0; 0.36.0 Requires-Python ~=3.9.0; 0.37.0 Requires-Python >=3.9.0,<3.11; 0.38.0 Requires-Python >=3.9.0,<3.11; 0.39.0 Requires-Python >=3.9.0,<3.11; 0.40.0 Requires-Python >=3.9.0,<3.11; 0.41.0 Requires-Python >=3.9.0,<3.11; 0.42.0 Requires-Python >=3.9.0,<3.11; 0.43.0 Requires-Python >=3.9.0,<3.11; 0.44.0 Requires-Python >=3.9.0,<3.11; 0.45.0 Requires-Python >=3.9.0,<3.11; 0.46.0 Requires-Python >=3.9.0,<3.11; 0.47.0 Requires-Python >=3.9.0,<3.11; 0.48.0 Requires-Python >=3.9.0,<3.11; 0.49.0 Requires-Python >=3.9.0,<3.11; 0.50.0 Requires-Python >=3.9.0,<3.11; 0.51.0 Requires-Python >=3.9.0,<3.11; 0.52.0 Requires-Python >=3.9.0,<3.11; 0.53.0 Requires-Python >=3.9.0,<3.11; 0.54.0 Requires-Python >=3.9.0,<3.11; 0.55.0 Requires-Python >=3.9.0,<3.11; 0.56.0 Requires-Python >=3.9.0,<3.11; 0.57.0 Requires-Python >=3.9.0,<3.11; 0.58.0 Requires-Python >=3.9.0,<3.11; 0.59.0 Requires-Python >=3.9.0,<3.11; 0.60.0 Requires-Python >=3.9.0,<3.11; 0.61.0 Requires-Python >=3.9.0,<3.11; 0.63.0 Requires-Python >=3.9.0,<3.11; 0.64.0 Requires-Python >=3.9,<3.12; 0.65.0 Requires-Python >=3.9,<3.12; 0.66.0 Requires-Python >=3.9,<3.12; 0.67.0 Requires-Python >=3.9,<3.12; 0.68.0 Requires-Python >=3.9,<3.12; 0.69.0 Requires-Python >=3.9,<3.12; 0.70.0 Requires-Python >=3.9,<3.12; 0.71.0 Requires-Python >=3.9,<3.12; 0.72.0 Requires-Python >=3.9,<3.12; 0.73.0 Requires-Python >=3.9,<3.12; 0.74.0 Requires-Python <3.12,>=3.9; 0.75.0 Requires-Python <3.12,>=3.9; 0.76.0 Requires-Python <3.12,>=3.9; 0.77.0 Requires-Python <3.12,>=3.9; 0.78.0 Requires-Python <3.12,>=3.9; 0.79.0 Requires-Python <3.12,>=3.9; 0.80.0 Requires-Python <3.12,>=3.9; 0.81.0 Requires-Python <3.12,>=3.9; 0.82.0 Requires-Python <3.12,>=3.9; 0.83.0 Requires-Python <3.12,>=3.9; 0.84.0 Requires-Python <3.12,>=3.9; 0.85.0 Requires-Python <3.12,>=3.9; 0.86.0 Requires-Python <3.12,>=3.9; 0.87.0 Requires-Python <3.12,>=3.9\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-federated==0.59.0 (from versions: 0.1.0, 0.2.0, 0.3.0, 0.4.0, 0.5.0, 0.6.0, 0.7.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.15.0, 0.16.0, 0.16.1, 0.17.0, 0.18.0, 0.19.0, 0.20.0, 0.21.0, 0.22.0, 0.23.0, 0.24.0, 0.26.0, 0.27.0, 0.28.0, 0.29.0, 0.30.0, 0.31.0, 0.32.0, 0.33.0)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-federated==0.59.0\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_federated as tff\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import Input, Dense\n","from sklearn.metrics import roc_auc_score\n","from collections import Counter\n","\n","# Set random seed for reproducibility\n","tf.random.set_seed(42)\n","\n","# --- 1. Load Data and Final Cleanup ---\n","print(\"1. Loading and Cleaning Data...\")\n","df_sampled = pd.read_csv(\"Dataset.csv\", low_memory=False)\n","\n","# A. Separate Features and Target\n","X = df_sampled.drop('Label', axis=1)\n","y = df_sampled['Label']\n","\n","# B. Cleanup: Drop leaky columns, handle NaNs\n","leaky_cols = [col for col in X.columns if 'Attack Category' in col]\n","leaky_cols.append('FTP Command Count')\n","X = X.drop(columns=leaky_cols, errors='ignore')\n","\n","nan_mask = y.isnull()\n","X = X[~nan_mask]; y = y[~nan_mask]\n","\n","for col in X.columns:\n","    X[col] = pd.to_numeric(X[col], errors='coerce')\n","X = X.fillna(0)\n","\n","# C. Define global variables and CRITICAL type casting\n","input_dim = X.shape[1]\n","NUM_CLIENTS = 10\n","\n","# Define the global test set (CRITICAL: Cast to float32 for model consistency)\n","X_test_global_np = X.to_numpy().astype('float32')\n","y_test_global_np = y.to_numpy().astype('float32')\n","print(f\"Data ready. Final feature count: {input_dim}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":433},"id":"Fhwrcy9ywjmQ","executionInfo":{"status":"error","timestamp":1759472973143,"user_tz":-330,"elapsed":3667,"user":{"displayName":"Mena Rossini R","userId":"03024307458201324126"}},"outputId":"f59a618d-eac4-4596-941e-6cfcc3deffc2"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow_federated'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1794075887.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_federated\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_federated'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["# -------------------------------------------------------------------\n","# 2. TFF DATA PARTITIONING AND PREPROCESSING\n","# -------------------------------------------------------------------\n","print(\"2. Partitioning Data for TFF Clients...\")\n","CLIENT_BATCH_SIZE = 32 # Use a small batch size for TFF\n","\n","def create_client_dataset(X_client):\n","    \"\"\"Converts a client's NumPy array into a TFF-compatible dataset.\"\"\"\n","    # Autoencoder uses X as both input and target for reconstruction (X, X)\n","    dataset = tf.data.Dataset.from_tensor_slices((X_client, X_client))\n","    # Shuffle, repeat, and batch for local training\n","    return dataset.shuffle(buffer_size=1000).batch(CLIENT_BATCH_SIZE).repeat(1)\n","\n","client_data_list = []\n","X_chunks = np.array_split(X, NUM_CLIENTS)\n","y_chunks = np.array_split(y, NUM_CLIENTS)\n","\n","for i in range(NUM_CLIENTS):\n","    # Only train on Normal data for the Autoencoder objective\n","    X_train_client, _, y_train_client, _ = train_test_split(\n","        X_chunks[i], y_chunks[i], test_size=0.3, random_state=42, stratify=y_chunks[i]\n","    )\n","    X_train_normal = X_train_client[y_train_client == 0].to_numpy().astype('float32')\n","\n","    client_data_list.append(create_client_dataset(X_train_normal))\n","\n","# TFF's simulation requires a list of client IDs\n","client_ids = [f'client_{i}' for i in range(NUM_CLIENTS)]\n","federated_train_data = tff.simulation.datasets.ClientData.from_clients_and_fn(\n","    client_ids=client_ids,\n","    create_tf_dataset_for_client_fn=lambda cid: client_data_list[int(cid.split('_')[1])]\n",")\n","print(f\"Data partitioned and converted to {len(client_ids)} TFF client datasets.\")\n","\n","\n","# -------------------------------------------------------------------\n","# 3. TFF MODEL DEFINITION (Using Keras)\n","# -------------------------------------------------------------------\n","def create_keras_autoencoder():\n","    # Encoder\n","    input_layer = tf.keras.Input(shape=(input_dim,), dtype=tf.float32)\n","    encoded = tf.keras.layers.Dense(64, activation='relu')(input_layer)\n","    bottleneck = tf.keras.layers.Dense(16, activation='relu', name='bottleneck')(encoded)\n","    # Decoder\n","    decoded = tf.keras.layers.Dense(64, activation='relu')(bottleneck)\n","    output_layer = tf.keras.layers.Dense(input_dim, activation='linear')(decoded)\n","\n","    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n","    return model\n","\n","# Define the model function wrapper TFF needs\n","def model_fn():\n","    model = create_keras_autoencoder()\n","    return tff.learning.from_keras_model(\n","        keras_model=model,\n","        input_spec=federated_train_data.element_type_structure,\n","        loss=tf.keras.losses.MeanSquaredError()\n","    )\n","print(\"3. TFF Autoencoder model defined.\")"],"metadata":{"id":"mqnT2NvbwnzF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------------------------------------------------------\n","# 4. TFF FEDERATED LEARNING PROCESS\n","# -------------------------------------------------------------------\n","\n","# Build the iterative process (TFF's equivalent of a strategy/server)\n","iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n","    model_fn=model_fn,\n","    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.001),\n","    server_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.01)\n",")\n","\n","# Initialize the state of the federated system (Round 0)\n","state = iterative_process.initialize()\n","NUM_ROUNDS = 10\n","print(f\"\\n4. Starting TFF Federated Simulation for {NUM_ROUNDS} rounds...\")\n","\n","# Run the simulation\n","history = []\n","for round_num in range(1, NUM_ROUNDS + 1):\n","    # Perform one round of federated training\n","    state, metrics = iterative_process.next(state, [\n","        federated_train_data.create_tf_dataset_for_client(cid)\n","        for cid in client_ids\n","    ])\n","\n","    # Extract the global model weights\n","    global_model_weights = tff.learning.models.weights_as_readonly_np(state.model)\n","\n","    # --- EVALUATION (Manual Reconstruction Error ROC-AUC) ---\n","\n","    # Load weights into a fresh Keras model for consistent evaluation\n","    eval_model = create_keras_autoencoder()\n","    eval_model.set_weights(global_model_weights.trainable)\n","\n","    # Calculate reconstruction error on the global test set\n","    reconstructions = eval_model.predict(X_test_global_np, verbose=0)\n","    mse = np.mean(np.power(X_test_global_np - reconstructions, 2), axis=1)\n","\n","    # Calculate ROC-AUC score (higher score = better separation)\n","    roc_auc = roc_auc_score(y_test_global_np, mse)\n","    history.append((round_num, roc_auc))\n","\n","    print(f\"Round {round_num:2d}: Global ROC-AUC = {roc_auc:.4f}\")\n","\n","print(\"\\nFederated Learning Simulation Complete (TFF).\")"],"metadata":{"id":"i2E5ayMNwpzL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load the final processed dataset\n","df = pd.read_csv(\"Dataset.csv\", low_memory=False)\n","\n","# The target column is always 'Label'. We exclude it from the feature count.\n","feature_columns = df.drop(columns=['Label'], errors='ignore').columns\n","\n","# Count the number of feature columns\n","final_feature_count = len(feature_columns)\n","\n","print(f\"Total Columns (including Label): {df.shape[1]}\")\n","print(f\"Feature Columns ONLY: {final_feature_count}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8oXwvKTz9cS0","executionInfo":{"status":"ok","timestamp":1759493151884,"user_tz":-330,"elapsed":1220,"user":{"displayName":"Mena Rossini R","userId":"03024307458201324126"}},"outputId":"801ea937-5d10-4b87-cf8b-47abd7fabdd8"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Columns (including Label): 215\n","Feature Columns ONLY: 214\n"]}]}]}