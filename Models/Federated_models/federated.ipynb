{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5JolxDmDxK2",
        "outputId": "5820e4f5-7bd1-46c8-9700-d10b33ad7dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Initial Data Loaded: 127732 rows.\n",
            "ðŸ”„ Cleaning non-numeric values (like ' ') into NaN...\n",
            "âœ… Data cleaned. 71684 rows dropped due to bad/missing values.\n",
            "Final training set size: 56048 rows.\n",
            "âœ… Global Test Set created: 11210 samples.\n",
            "âœ… Training data split into 3 federated nodes.\n",
            "Node 1 training samples: 14796\n",
            "Node 2 training samples: 15021\n",
            "Node 3 training samples: 15021\n",
            "\n",
            "--- Part 1: Data Preparation & Cleaning Complete ---\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter\n",
        "\n",
        "# --- 1. Load Data (Suppress DtypeWarning) ---\n",
        "try:\n",
        "    # Use low_memory=False to better handle mixed types during load\n",
        "    data = pd.read_csv(\"Dataset.csv\", low_memory=False)\n",
        "    print(f\"âœ… Initial Data Loaded: {len(data)} rows.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"âŒ ERROR: 'Dataset.csv' not found. Please ensure the file is in the correct directory.\")\n",
        "    raise\n",
        "\n",
        "# --- 2. Initial Cleaning and Feature Engineering ---\n",
        "# Assuming 'Label' or a column related to 'attack_cat' is the target\n",
        "target_col = 'label'\n",
        "if 'Label' in data.columns:\n",
        "    data[target_col] = data['Label']\n",
        "elif 'attack_cat' in data.columns:\n",
        "    # Example for UNSW-NB15 dataset: create binary label from 'attack_cat'\n",
        "    data[target_col] = np.where(data['attack_cat'] == 'Normal', 0, 1)\n",
        "else:\n",
        "    print(\"âŒ ERROR: Could not find a suitable target column ('Label' or 'attack_cat').\")\n",
        "    raise\n",
        "\n",
        "# Drop redundant/non-numeric columns that should NOT be scaled\n",
        "data.drop(columns=['Label', 'attack_cat', 'id', 'ts', 'proto', 'service', 'state', 'ct_flw_http_mthd'],\n",
        "          errors='ignore', inplace=True)\n",
        "\n",
        "# --- 3. CRITICAL FIX: Coerce non-numeric columns to numeric ---\n",
        "# Identify all columns that are NOT the target label\n",
        "feature_cols = data.columns.drop(target_col)\n",
        "\n",
        "# Convert all feature columns to a numeric type, forcing errors (like ' ') into NaN\n",
        "print(\"ðŸ”„ Cleaning non-numeric values (like ' ') into NaN...\")\n",
        "for col in feature_cols:\n",
        "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
        "\n",
        "# Drop any rows with remaining NaN/infinity after conversion\n",
        "initial_rows = len(data)\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.dropna(inplace=True)\n",
        "print(f\"âœ… Data cleaned. {initial_rows - len(data)} rows dropped due to bad/missing values.\")\n",
        "print(f\"Final training set size: {len(data)} rows.\")\n",
        "\n",
        "# --- 4. Split into Global Test Set and Training Data ---\n",
        "X = data.drop(target_col, axis=1)\n",
        "y = data[target_col]\n",
        "\n",
        "X_train_full, X_test_global, y_train_full, y_test_global = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "X_test_global_np = X_test_global.values\n",
        "y_test_global_np = y_test_global.values\n",
        "print(f\"âœ… Global Test Set created: {len(X_test_global)} samples.\")\n",
        "\n",
        "# --- 5. Scale Data and Extract Training Features ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_full) # This will now work!\n",
        "X_train_fif = X_train_scaled # Use all features after cleaning and scaling\n",
        "\n",
        "# --- 6. Split Training Data into Federated Nodes (Clients) ---\n",
        "X_train_df = pd.DataFrame(X_train_fif)\n",
        "y_train_df = pd.Series(y_train_full.values, name=target_col)\n",
        "combined_train_data = pd.concat([X_train_df, y_train_df], axis=1)\n",
        "\n",
        "# Split into 3 non-overlapping client nodes (IID simulation)\n",
        "node_1, temp = train_test_split(combined_train_data, test_size=0.67, random_state=42)\n",
        "node_2, node_3 = train_test_split(temp, test_size=0.5, random_state=42)\n",
        "\n",
        "federated_nodes = [node_1, node_2, node_3]\n",
        "print(f\"âœ… Training data split into {len(federated_nodes)} federated nodes.\")\n",
        "\n",
        "# Prepare X and y lists for client training\n",
        "X_nodes_fif, y_nodes_fif = [], []\n",
        "for i, node in enumerate(federated_nodes):\n",
        "    X = node.drop(target_col, axis=1).values\n",
        "    y = node[target_col].values\n",
        "    X_nodes_fif.append(X)\n",
        "    y_nodes_fif.append(y)\n",
        "    print(f\"Node {i+1} training samples: {len(X)}\")\n",
        "\n",
        "print(\"\\n--- Part 1: Data Preparation & Cleaning Complete ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X_nodes_fif, X_test_global_np, y_train_full, and y_test_global_np are in memory\n",
        "\n",
        "# --- 1. Determine Contamination Rate ---\n",
        "# Isolation Forest requires an estimate of the anomaly proportion.\n",
        "contamination_rate = Counter(y_train_full)[1] / len(y_train_full)\n",
        "print(f\"Using Contamination Rate from training data: {contamination_rate:.4f}\\n\")\n",
        "\n",
        "# --- 2. Train Local Models ---\n",
        "local_if_models = []\n",
        "for i, X_local in enumerate(X_nodes_fif):\n",
        "    # Isolation Forest only needs the features (X) for training\n",
        "    model = IsolationForest(\n",
        "        n_estimators=100,\n",
        "        contamination=contamination_rate,\n",
        "        random_state=42,\n",
        "        bootstrap=False\n",
        "    )\n",
        "    model.fit(X_local)\n",
        "    local_if_models.append(model)\n",
        "    print(f\"ðŸŒ¿ Trained local Isolation Forest model {i+1}\")\n",
        "\n",
        "# --- 3. Federated Prediction Function (Simulated FedAvg) ---\n",
        "def federated_if_predict(X_global_test):\n",
        "    \"\"\"Aggregates anomaly scores by averaging decision functions.\"\"\"\n",
        "    scores = []\n",
        "    for model in local_if_models:\n",
        "        # Negate the decision function so a higher score means a higher anomaly likelihood.\n",
        "        local_scores = -model.decision_function(X_global_test)\n",
        "        scores.append(local_scores)\n",
        "\n",
        "    # Average the anomaly scores from all local models\n",
        "    avg_scores = np.mean(scores, axis=0)\n",
        "    return avg_scores\n",
        "\n",
        "print(\"\\n--- Part 2: Federated Training Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lCgZchIFqsy",
        "outputId": "864f16a7-245e-4fbe-f607-3b2c1312a799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Contamination Rate from training data: 0.0218\n",
            "\n",
            "ðŸŒ¿ Trained local Isolation Forest model 1\n",
            "ðŸŒ¿ Trained local Isolation Forest model 2\n",
            "ðŸŒ¿ Trained local Isolation Forest model 3\n",
            "\n",
            "--- Part 2: Federated Training Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# --- 1. Calculate the Simulated Federated Score (F-IF) ---\n",
        "print(\"Calculating Federated Anomaly Scores on Global Test Set...\")\n",
        "federated_scores = federated_if_predict(X_test_global_np)\n",
        "federated_roc_auc = roc_auc_score(y_test_global_np, federated_scores)\n",
        "\n",
        "# --- 2. Calculate the Local-Only Baseline (L-IF) ---\n",
        "# We use only Node 1's model (the first local model) to get the worst-case scenario.\n",
        "local_only_roc_auc = roc_auc_score(y_test_global_np, -local_if_models[0].decision_function(X_test_global_np))\n",
        "\n",
        "print(\"\\n--- FINAL BENCHMARK RESULTS ---\")\n",
        "print(f\"Local-Only IF (Worst-Case): {local_only_roc_auc:.4f}\")\n",
        "print(f\"Simulated Federated IF: {federated_roc_auc:.4f}\")\n",
        "\n",
        "# --- 3. Final Conclusion Framing ---\n",
        "if federated_roc_auc > local_only_roc_auc:\n",
        "    print(\"\\nâœ… SUCCESS: The collaborative Federated Model (F-IF) significantly outperforms the isolated Local-Only Model (L-IF).\")\n",
        "    print(\"This result is the core proof for your paper: Collaboration improves security performance!\")\n",
        "elif abs(federated_roc_auc - local_only_roc_auc) < 0.01:\n",
        "    print(\"\\nâš ï¸ Note: The scores are very close. Your paper should discuss how FL achieves near-centralized performance while preserving data privacy.\")\n",
        "else:\n",
        "    print(\"\\nâŒ Unexpected Result: The local model performed better. Review the data for heavy Non-IID distribution.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwe-01mfFw9u",
        "outputId": "941177c6-2f83-4f87-c3e4-8016ae870c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Federated Anomaly Scores on Global Test Set...\n",
            "\n",
            "--- FINAL BENCHMARK RESULTS ---\n",
            "Local-Only IF (Worst-Case): 0.8903\n",
            "Simulated Federated IF: 0.8003\n",
            "\n",
            "âŒ Unexpected Result: The local model performed better. Review the data for heavy Non-IID distribution.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Assuming X_train_full, X_test_global_np, and y_test_global_np are in memory\n",
        "# X_train_full was already scaled into X_train_fif\n",
        "\n",
        "# --- 1. Determine Contamination Rate (Use the training full data) ---\n",
        "contamination_rate = Counter(y_train_full)[1] / len(y_train_full)\n",
        "print(f\"Using Contamination Rate: {contamination_rate:.4f}\\n\")\n",
        "\n",
        "# --- 2. Train the Centralized Model ---\n",
        "print(\"Training Centralized Isolation Forest Model (C-IF)...\")\n",
        "\n",
        "centralized_model = IsolationForest(\n",
        "    n_estimators=100,\n",
        "    contamination=contamination_rate,\n",
        "    random_state=42,\n",
        "    bootstrap=False\n",
        ")\n",
        "# Train on the entire training data (X_train_fif)\n",
        "centralized_model.fit(X_train_fif)\n",
        "\n",
        "# --- 3. Evaluate the Centralized Model ---\n",
        "centralized_scores = -centralized_model.decision_function(X_test_global_np)\n",
        "centralized_roc_auc = roc_auc_score(y_test_global_np, centralized_scores)\n",
        "\n",
        "print(\"\\n--- FINAL BENCHMARK: CENTRALIZED MODEL ---\")\n",
        "print(f\"Centralized Isolation Forest ROC-AUC (C-IF): {centralized_roc_auc:.4f}\")\n",
        "\n",
        "# --- 4. Final Comparison Summary ---\n",
        "L_IF = 0.8903\n",
        "F_IF = 0.8003\n",
        "\n",
        "print(\"\\n--- Project's Final Data Summary ---\")\n",
        "print(f\"1. Centralized (Ideal Ceiling): {centralized_roc_auc:.4f}\")\n",
        "print(f\"2. Local-Only (Single Client): {L_IF:.4f}\")\n",
        "print(f\"3. Simulated Federated (Collaboration Failure): {F_IF:.4f}\")\n",
        "\n",
        "if centralized_roc_auc > L_IF:\n",
        "    print(\"\\nðŸ’¡ Conclusion: Your paper will argue that while C-IF is the best, FL's poor performance (F-IF) under Non-IID conditions means the L-IF approach is a necessary, albeit suboptimal, choice until advanced FL techniques are used.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEyYTSq-GLcN",
        "outputId": "8410f616-87c3-457b-b5bd-2edb6412a2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Contamination Rate: 0.0218\n",
            "\n",
            "Training Centralized Isolation Forest Model (C-IF)...\n",
            "\n",
            "--- FINAL BENCHMARK: CENTRALIZED MODEL ---\n",
            "Centralized Isolation Forest ROC-AUC (C-IF): 0.8192\n",
            "\n",
            "--- Project's Final Data Summary ---\n",
            "1. Centralized (Ideal Ceiling): 0.8192\n",
            "2. Local-Only (Single Client): 0.8903\n",
            "3. Simulated Federated (Collaboration Failure): 0.8003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hSGUCRmTGLZb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}